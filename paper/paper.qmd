---
title: "Stream of Consciousness Literature: A 'Joyceless' Linguistic Landscape" 
subtitle: "Exploring Word Frequency, Sentiment Value and Mental Health Themes in the Works of Joyce, Woolf, Proust, Mansfield and Eliot from Project Gutenberg"
author: Quang Mai
thanks: "Code and data are available at: https://github.com/ponolite/stream-consciousness-language.git"
date: today
date-format: long
abstract: "This project focuses on understanding the language used by renowned stream of consciousness (SOC) authors James Joyce, Virginia Woolf, Marcel Proust, Katherine Mansfield and T.S Eliot. By conducting word frequency analysis and sentiment analysis on these authors' nine novels, this paper aims to uncover shared linguistic patterns and gain insights into the authors' mental states. This paper attempts to offer insights into themes of self-identity, anxiety, disassociation and existential contemplation within Western society and its literary circle from late 19th to mid-20th century. (add one sentence on main results)"
format: pdf
number-sections: true
bibliography: references.bib
toc: true
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(tidytext)
library(rmarkdown)
library(gutenbergr)
library(tm)
library(dplyr)
library(ggplot2)
library(scales)
library(knitr)
library(igraph)
library(widyr)
library(ggraph)
library(textdata)
library(arrow)


portrait_clean <- read_parquet(here::here("data/analysis_data/portrait_clean.parquet"))
portrait_words <- read_parquet(here::here("data/analysis_data/portrait_words.parquet"))
swann_words <- read_parquet(here::here("data/analysis_data/swann_words.parquet"))
dalloway_words <- read_parquet(here::here("data/analysis_data/dalloway_words.parquet"))
bliss_words <- read_parquet(here::here("data/analysis_data/bliss_words.parquet"))
prufrock_words <- read_parquet(here::here("data/analysis_data/prufrock_words.parquet"))
combined_text <- read_parquet(here::here("data/analysis_data/combined_text.parquet"))
portrait <- read_csv(here::here("data/raw_data/portrait.csv"))
all_books <- read_csv(here::here("data/raw_data/all_books.csv"))
combined_books <- read_csv(here::here("data/raw_data/combined_books.csv"))

```

# Introduction

Stream of consciousness (SOC) is a narrative technique that aims to capture the continuous flow of thoughts, feelings, and sensations experienced by a character without conventional organization or punctuation [@resampling]. It mirrors the unpredictable and interconnected nature of human thought processes, often revealing the inner workings of the character's mind in an intimate and unfiltered manner [@flow]. In literature, most scholars agree that stream of consciousness reveals the complexities of mind-scapes, shedding light on the nuances of characters' emotional well-being and psychological struggles [@pathology]. As such, this paper has mined the texts of a total of nine novels from the volunteer archive, Project Gutenberg, to examine the mental health themes of famous stream of consciousness authors, namely by Joyce, Woolf, Proust, Mansfield and Eliot, from the modernist era of literature, spanning from late 19th century to mid-20th century [@gutenberg]. (more stats and data mentioned here)

By analyzing these textual datasets through word frequency and sentiment analysis, I seek to pose and answer crucial questions: \textit{What are some important factors contributing to this relationship between mental health, disassociation and stream of consciousness? Moreover, how does this relationship vary differently across differnet demographics of authors, for instance, authors with different geographical locations and genders?} Understanding these dynamics is crucial in having an informed understanding of the West's late 19th to mid-20th century literature and even socio-political landscape, especially in regards to how authors and creative writers navigate and deal with then-taboo topics such as existential angst, mental health issues and disabilities.

Thus, my estimand is the correlation between mental health-related words in SOC literature, their frequency and sentiment value as provided by @Tidytext. This is considered in terms of nine selected SOC novels only, namely Joyce's \textit{A Portrait of the Artist as a Young Man and Chamber Music}; Woolf's \textit{Mrs Dalloway and Jacob's Room}; Proust's \textit{Swann Way}; Mansfield's \textit{Bliss and The Garden Party}; and Eliot's \textit{The Waste Land and The Love Song of J. Alfred Prufrock}. Through our analysis, we found that (percentage, number and data here, main results)...

To further understand the correlation between stream of consciousness novels and mental health themes, in [Introduction], the paper briefly discusses the nature of stream of consciousness literature, relevant authors and the works that I've chosen to analyze. Subsequently, in [Data] and [Results], I talk about the nature of the data obtained and analyze the results garnered from the data with suitable tables and charts. Next, [Discussion] provides further insights and future areas of study. Finally, [Conclusion] summarizes our main findings. To complete the paper, [Appendix] clarifies how each variable within each dataset is generated with relevant tables to accordingly demonstrate this.

The novel texts used for analysis were sourced from Project Gutenberg under the library `gutenbergr` [@rGuten] [@gutenberg]. Data was generated, extracted and cleaned using the open-source statistical programming language R [@r], leveraging functions from `tidyverse` [@rTidyverse], `tidytext` [@rTidytext], `rmarkdown` [@rMark], `dplyr` [@rDplyr], `ggplot2` [@rGgplot2], `scales` [@rScales], `here` [@rHere], `igraph` [@rIgraph], `widyr` [@rWidy], `ggraph` [@rGg], `textdata` [@rTextdata], `tm` [@rTm], `here` [@here], `arrow` [@arrow], and `knitr` [@rKnitr].

# Data {#sec-data}

## Measurement

Two central variables in this paper are:

* **Word Frequency:** This variable captures the repetition of a single word (unigram), two-words combination (bigram) or three-words combination (trigram) throughout a SOC novel text, providing us with a thematic understanding of SOC literature.
* **Sentiment Value:** This variable enables us to analyze how every word is usually perceived emotionally, whether it be a qualitative feeling or if it is conveyed through a numerical value.

Out of two variables used, the first one, 'Word Frequency' usually captured as `n` or `frequency` in datasets, is directly quantified through tokenizing the novel texts using the package `tidytext` and its function `unnest_tokens()` [@rTidytext]. To do this, I first downloaded all nine novel texts from @gutenberg, and leveraged functions such as `unnest_tokens()` from @rTidytext to mine the texts, or separating it into individual words. Finally, I used `count()` to quantify the word frequency. 

The second variable used, 'Sentiment Value', is based on three English-based, general-purpose  "word-emotion and word-polarity association lexicons", sourced from Mohammad and Turney's expansive research along with efforts from Finn Årup Nielsen and Bing Liu and collaborators [@rTidytext] [@sentiment]. The three general-purpose lexicon that contributes to my sentiment analysis are [@rTidytext]:

- 'AFINN' from Finn Årup Nielsen, which assigns a numerical value from '-5 to 5' 
- 'bing' from Bing Liu and collaborators, which assigns if a word is 'positive' or negative'
- 'nrc' from Saif Mohammad and Peter Turney, which assigns a core emotional value to a word, such as 'fear', 'anger', 'sadness' or 'trust'.

In terms of measuring 'Sentiment Value', all three general-purpose lexicons are compiled through crowd-sourcing and directly surveying the public on how each word is emotionally perceived. A survey sample of how the word 'startle' is compiled within the 'nrc' lexicon is presented below [@sentiment]:

(@) Which word is closest in meaning (most related) to startle?
- automobile
- shake
- honesty
- entertain

(@) How positive (good, praising) is the word startle?:
- startle is not positive
- startle is weakly positive
- startle is moderately positive
- startle is strongly positive

(@) How negative (bad, criticizing) is the word startle?
- startle is not negative
- startle is weakly negative
- startle is moderately negative
- startle is strongly negative

After the survey results are garnered, researchers average the answers to sort each surveyed word into pre-defined categories, specifically '-5 to 5' for 'AFINN', 'postive' or 'negative' for 'bing', and 'anger' or 'fear' for 'nrc'. With the continuous work of compiling these lexicons spanning years and decades [@sentiment] comes these functions: `get_sentiments("bing")` and `get_sentiments("nrc")` and `get_sentiments("afinn")` in which I can use `inner_join` to categorize my existing datasets of novel texts into their sentiment value. Systematic and data-driven, these measurement methods ensure that all lexicons faithfully reflects each word's emotionality.

However, I do recognize how decontextualized and reductive this quantification of language can be. When it comes to understand such social and human artifacts as language or literary texts, much is dependent on their contextuality. As such, I will further discuss these weaknesses of the datasets under [Discussion].

## Source Data: Data Cleaning and Word Tokenization

Founded in December 1, 1971 by Michael S. Hart, Project Gutenberg exclusively publishes literature in the public domain within the United States. Typically, submissions to Project Gutenberg are digitized editions of printed books, the majority of which were published over 95 years ago. To confirm public domain status, authors can utilize the copy.pglaf.org website [@gutenberg].

Since the archive is largely supported by voluntary works, its literature is also selected by volunteers. However, the archive doesn't accept copyrighted or other contemporary items, even if copyright or licensing permission would be granted.

To submit work to the archive involves obtaining copyright, then scanning or harvesting to obtain images of a book's pages, then engaging in various hours of proofreading and formatting, and finally, ensuring the eBook is fully valid HTML, correctly spelled, and otherwise compliant with Project Gutenberg’s requirements,
Collection development focuses on literature and other written works that have enduring value for readers. Selections are made by volunteers with diverse interests, and essentially all eligible submissions are welcome.


COMMON POINTS OF FAILURE

Crop marks or other printer's marks should not be used on any files.
The book description should be in compliance with the rules listed here.
Missing Pages
Title missing on the front cover
Incorrect pagination
Books with typographical errors, such as misspellings or poor grammar.


Project Gutenberg does not avoid difficult or unpopular topics, or topics for which societal views, or state-of-the-art knowledge, is vastly different from contemporary literature.

Project Gutenberg does not accept copyrighted or other contemporary items, even if copyright or licensing permission would be granted (this includes the various “open” licenses). Instead, see the self-publishing portal described in the Submitting Your own Work How-To. In the past, a greater variety of non-public domain and non-literary works was added to Project Gutenberg, including copyrighted & other donated works, non-print formats, and different encodings and file types. Today, there are many outlets for such other items, and Project Gutenberg is entirely focused on works in the public domain. This includes literature, reference works, and variations such as children’s books and travelogues.

Who should submit an eBook?

Creating an eBook is a lot of work, and Project Gutenberg’s requirements are rather strict. If these steps seem daunting, you might be better off working with Distributed Proofreaders, where every volunteer contributes to a portion of the effort. Distributed Proofreaders has its own guidelines on submissions, as well as other policy, guidance, and community.

Being a “solo” producer involves obtaining copyright, then scanning or harvesting to obtain images of a book’s pages, then engaging in many hours of proofreading and formatting, and, finally, ensuring the eBook is fully valid HTML, correctly spelled, and otherwise compliant with Project Gutenberg’s requirements. The detailed requirements are on the submission page, which also includes tools for automatically checking compliance. Any new submitter is invited to get in touch before to getting started. Contact the “copyright” or “whitewashers” team &emdash; email addresses are at the bottom of the copyright and upload sites.

Copyright

The first step in any eBook submission is to confirm that Project Gutenberg may legally distribute the eBook. Visit our Copyright How-To for details. Project Gutenberg will not accept any eBook without confirming copyright status. Generally, this means that a printed book has entered the public domain in the United States, typically because copyright has expired.

File Formats

The master format for nearly all new Project Gutenberg eBooks is HTML. Project Gutenberg insists the HTML is fully valid, and any cascading style sheets (CSS) in the HTML are part of the published standards by the World Wide Web consortium (W3C).

Whenever possible, Project Gutenberg also requires a plain text version of an eBook. We stress the inclusion of plain text because of its longevity: Project Gutenberg includes numerous text files that are over 30 years old. In that time, dozens of widely used file formats have come and gone. Text is accessible on all computers, and is also insurance against future obsolescence.

The only times when Project Gutenberg distributes an eBook without a plain text version are when plain text is impossible or impractical — for example, for our movies and MP3 audio files, and for some of our mathematical works.

This isn’t as hard as it sounds, if you start with HTML, and continuously confirm validity using the W3C’s online validator (see the upload page for details). Modern eBook producers almost always start with (valid) HTML, and then derive plain text from the HTML. These two “master” formats, text and HTML, are then submitted to Project Gutenberg. Automated tools then create derivative formats, including epub and mobi (the common e-reader formats).

Hand-crafted epub and mobi files are not accepted, currently. This limitation is mainly to allow easy editing when fixes are applied, because application of fixes occurs many times over the lifetime of every eBook. Project Gutenberg tries to limit the number of master formats, and then automate derived formats, to facilitate continuous improvement of items in the collection.

A small number of new eBooks utilize LaTeX or TEI as the master format - mostly those including lots of mathematical notation. Other less frequently utilized formats include ReSstructured Text (RST), Rich Data Format (RDF), and a few others. Note that PDF, Word, and other word processor formats are not utilized as master formats, because they do not convert easily to valid HTML. In addition, they are much more challenging to fix/update than HTML and plain text.



Discuss the authenticity/validity of Project Gutenberg

### Word Count

```{r}
#| echo: false
#| eval: true
#| label: tbl-joyce
#| tbl-cap: "An Examplary Table Containing Unprocessed Novel Text (James Joyce)"
#| warning: false

portrait |>
  rename("Book ID" = gutenberg_id,
         "Text" = text,
         "Book" = book,
         "Author" = author) |>
  head(5) |>
  kable(
    col.names = c("Book ID", "Text", "Book", "Author"),
    booktabs = TRUE
  )

```


```{r}
#| echo: false
#| eval: true
#| label: tbl-joyce-token
#| tbl-cap: "An Examplary Table Containing Tokenzied Novel Text (James Joyce)"
#| warning: false

portrait_clean |>
  rename("Book ID" = gutenberg_id,
         "Book" = book,
         "Author" = author,
         "Word" = word) |>
  tail(5) |>
  kable(
    col.names = c("Book ID", "Book", "Author", "Word"),
    booktabs = TRUE
  )

```
\newpage

```{r}
#| echo: false
#| eval: true
#| label: tbl-joyce-words
#| tbl-cap: "An Examplary Table Containing Word Count of Each Word within Novel Texts (James Joyce)"
#| warning: false

portrait_words |>
  rename("Word" = word) |>
  head(5) |>
  kable(
    col.names = c("Word", "Count"),
    booktabs = TRUE
  )

```

### Comparative Word Frequency

```{r}
#| echo: false
#| eval: true
#| label: tbl-frequency
#| tbl-cap: "Word Frequency of Stream of Consciousness Novels, A Comparison Between Five Authors "
#| warning: false

frequency <- bind_rows(mutate(portrait_words, author = "James Joyce"),
                       mutate(swann_words, author = "Marcel Proust"),
                       mutate(dalloway_words, author = "Virginia Woolf"),
                       mutate(bliss_words, author = "Katherine Mansfield"),
                       mutate(prufrock_words, author = "T.S. Eliot")) |>
  mutate(word = str_extract(word, "[a-z']+")) |>
  count(author, word) |>
  group_by(author) |>
  mutate(proportion = n / sum(n)) |>
  select(-n) |>
  pivot_wider(names_from = author, values_from = proportion) 

frequency |>
  rename("Word" = word) |>
  head(5) |>
  kable(
    col.names = c("Word", "James Joyce", "Katherine Mansfield", "Marcel Proust", "T.S. Eliot", "Virignia Woolf"),
    booktabs = TRUE
  )

```

### Generating Word Networks

## Data Limitations

# Model

The goal of our modelling strategy is twofold. Firstly,...

Here we briefly describe the Bayesian analysis model used to investigate... Background details and diagnostics are included in [Appendix -@sec-model-details].


## Model set-up

Define $y_i$ as the number of seconds that the plane remained aloft. Then $\beta_i$ is the wing width and $\gamma_i$ is the wing length, both measured in millimeters.  

\begin{align} 
y_i|\mu_i, \sigma &\sim \mbox{Normal}(\mu_i, \sigma) \\
\mu_i &= \alpha + \beta_i + \gamma_i\\
\alpha &\sim \mbox{Normal}(0, 2.5) \\
\beta &\sim \mbox{Normal}(0, 2.5) \\
\gamma &\sim \mbox{Normal}(0, 2.5) \\
\sigma &\sim \mbox{Exponential}(1)
\end{align}

We run the model in R [@citeR] using the `rstanarm` package of @rstanarm. We use the default priors from `rstanarm`.

### Model justification

We expect a negative relationship between average household income and the number of children per child care space by ward. In particular...

We can use maths by including latex between dollar signs, for instance $\theta$.


# Results

## The Dominant Vocabulary of SOC Literature

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-count
#| layout-ncol: 2
#| fig-cap: "Comparative Analysis of Top 20 Word Frequencies from Famous SOC Authors"
#| fig-subcap: ["James Joyce", "Virginia Woolf", "Marcel Proust", "T.S. Eliot", "Katherine Mansfield"]

portrait_words |> head(20) |>
ggplot(aes(x = n, y = reorder(word, n))) +
  geom_bar(stat = "identity", fill = "darkgrey") +
  labs(x = "Frequency", y = "Word")

dalloway_words |> head(20) |>
ggplot(aes(x = n, y = reorder(word, n))) +
  geom_bar(stat = "identity", fill = "darkgrey") +
  labs(x = "Frequency", y = "Word")

swann_words |> head(20) |>
ggplot(aes(x = n, y = reorder(word, n))) +
  geom_bar(stat = "identity", fill = "darkgrey") +
  labs(x = "Frequency", y = "Word")

prufrock_words |> head(20) |>
ggplot(aes(x = n, y = reorder(word, n))) +
  geom_bar(stat = "identity", fill = "darkgrey") +
  labs(x = "Frequency", y = "Word")

bliss_words |> head(20) |>
ggplot(aes(x = n, y = reorder(word, n))) +
  geom_bar(stat = "identity", fill = "darkgrey") +
  labs(x = "Frequency", y = "Word") 


```
\newpage

## Sentiment Analysis

Leveraging setiment analysis from @sentiment

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-sentiment-category
#| layout-ncol: 2
#| fig-cap: "Categorical Sentiment Analysis of All SOC Novel Texts by Authors"
#| fig-subcap: ["Bing lexicon", "NRC lexicon"]

bing_lexicon <- get_sentiments("bing") %>%
  rename(sentiment_binary = sentiment)

sentiment_combined <- combined_text |>
  inner_join(bing_lexicon) |>
  inner_join(get_sentiments("afinn")) |>
  inner_join(get_sentiments("nrc"))

sentiment_category_binary <- sentiment_combined |>
  group_by(author, sentiment_binary) |>
  count() |>
  group_by(author) |>
  mutate(percentage = n / sum(n) * 100)  

# Plot sentiment values
ggplot(sentiment_category_binary, aes(x = author, fill = sentiment_binary, y = percentage)) +
  geom_bar(stat = "identity") +
  labs(
       x = "Author", y = "Percentage") +
  scale_fill_manual(values = c("positive" = "gray80", "negative" = "gray20", "neutral" = "gray50")) + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

sentiment_category <- sentiment_combined |>
  group_by(author, sentiment) |>
  count() |>
  group_by(author) |>
  mutate(percentage = n / sum(n) * 100)  |>
  group_by(author) |>
  arrange(desc(percentage))

# Plot sentiment values
ggplot(sentiment_category, aes(x = author, fill = sentiment, y = percentage)) +
  geom_bar(stat = "identity") +
  labs(
       x = "Author", y = "Percentage") +
  scale_fill_manual(values = c("negative" = "gray1", "sadness" = "gray10", "anger" = "gray20", "disgust" = "gray30", "fear" = "gray40", "joy" = "gray50", "trust" = "gray60", "anticipation" = "gray70", "positive" = "gray80", "surprise" = "gray90")) + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-sentiment-number
#| fig-cap: "Numerical Sentiment Analysis of All SOC Novel Texts by Authors (AFINN lexicon)"

sentiment_value <- sentiment_combined |>
  inner_join(get_sentiments("bing")) |>
  group_by(author, value, sentiment) |>
  count() |>
  group_by(author) |>
  mutate(percentage = n / sum(n) * 100)  

ggplot(sentiment_value, aes(x = value, y = percentage, color = sentiment, group = sentiment)) +
  geom_line() +
  facet_wrap(~ author, scales = "free") +
  labs(
       x = "Sentiment Value", y = "Percentage") +
  scale_color_manual(values = c("positive" = "black", "negative" = "gray")) + # Adjust line colors
  theme_minimal()
```


## Gendered Mental Landscape of Stream of Consciousness Novels

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-word-gender
#| layout-ncol: 2
#| fig-cap: "Comparative Analysis of Word Frequency in Female and Male Stream of Consciousness Authors"
#| fig-subcap: ["Female Authors", "Male Authors"]


# Calculate the word frequency over all unique words and bind all frequency rate of authors together to conduct a comparative comparison
# Code referenced from https://medium.com/the-data-nudge/nlp-basics-exploring-word-frequency-with-the-tidytext-r-package-ac35a6d805f4

  
frequency_female <- bind_rows(mutate(dalloway_words, author = "Virginia Woolf"),
                              mutate(bliss_words, author = "Katherine Mansfield")) |>
  mutate(word = str_extract(word, "[a-z']+")) |>
  count(author, word) |>
  group_by(author) |>
  mutate(proportion = n / sum(n)) |>
  select(-n) |>
  pivot_wider(names_from = author, values_from = proportion) |>
  pivot_longer(`Virginia Woolf`,
               names_to = "author", values_to = "proportion")

ggplot(frequency_female, aes(x = proportion, y = `Katherine Mansfield`, color = abs(`Katherine Mansfield` - proportion))) +
  geom_abline(color = "gray50", lty = 2) +
  geom_jitter(alpha = 0.1, size = 1, width = 0.5, height = 0.5) +  
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = scales::percent_format()) +
  scale_y_log10(labels = scales::percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), 
                       low = "blue2", high = "gray50") +
  facet_wrap(~author, ncol = 1) +
  theme(legend.position="none") +
  labs(y = "Katherine Mansfield", x = NULL)

frequency_male <- bind_rows(
                       mutate(swann_words, author = "Marcel Proust"),
                       mutate(prufrock_words, author = "T.S. Eliot"),
                       mutate(portrait_words, author = "James Joyce")) |>
  mutate(word = str_extract(word, "[a-z']+")) |>
  count(author, word) |>
  group_by(author) |>
  mutate(proportion = n / sum(n)) |>
  select(-n) |>
  pivot_wider(names_from = author, values_from = proportion) |>
  pivot_longer(`Marcel Proust`:`James Joyce`,
               names_to = "author", values_to = "proportion")

ggplot(frequency_male, aes(x = proportion, y = `T.S. Eliot`, color = abs(`T.S. Eliot` - proportion))) +
  geom_abline(color = "gray50", lty = 2) +
  geom_jitter(alpha = 0.1, size = 1.5, width = 0.8, height = 0.8) +  
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), 
                       low = "blue2", high = "gray100") +
  facet_wrap(~author, ncol = 2) +
  theme(legend.position="none") +
  labs(y = "T.S. Eliot", x = NULL)


```

### Comparing SOC Literature's Female Authors

### Comparing SOC Literature's Male Authors

## Transnational SOC Novels and Mental Health Themes

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-frequency-int
#| fig-cap: "Comparative Analysis of Word Frequency in Transnational Stream of Consciousness Authors"

frequency_international <- bind_rows(
                       mutate(swann_words, author = "Marcel Proust"),
                       mutate(bliss_words, author = "Katherine Mansfield"),
                       mutate(portrait_words, author = "James Joyce")) |>
  mutate(word = str_extract(word, "[a-z']+")) |>
  count(author, word) |>
  group_by(author) |>
  mutate(proportion = n / sum(n)) |>
  select(-n) |>
  pivot_wider(names_from = author, values_from = proportion) |>
  pivot_longer(`Katherine Mansfield`:`James Joyce`,
               names_to = "author", values_to = "proportion")

ggplot(frequency_international, aes(x = proportion, y = `Marcel Proust`, color = abs(`Marcel Proust` - proportion))) +
  geom_abline(color = "gray50", lty = 2) +
  geom_jitter(alpha = 0.05, size = 1, width = 0.8, height = 0.8) +  
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), 
                       low = "blue2", high = "gray100") +
  facet_wrap(~author, ncol = 1) +
  theme(legend.position="none") +
  labs(y = "Marcel Proust", x = NULL)

```

## Combined Texts: Trends, Word Networks, Bigram and Trigram Analsis

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false

## Code sourced from https://www.youtube.com/watch?v=ae_XVhjHd_o

generate_word_graph <- function(combined_text,
                                minimum_n = 100,
                                minimum_correlation = 0.2) {

combined_text_count <- combined_text |>
  count(word, sort = TRUE) |>
  filter(n >= 200) 

combined_correlations <- combined_text |>
  semi_join(combined_text_count, by = "word") |>
  pairwise_cor(item = word, feature = book) |>
  filter(correlation >= 0.2)

graph_from_data_frame(d = combined_correlations, #create graphs of networks of words
                      vertices = combined_text_count |>
                      semi_join(combined_correlations, by = c("word" = "item1"))) |>
  ggraph(layout = "fr") +
  geom_edge_link(aes(alpha = correlation), alpha = 0.05) +
  geom_node_point() +
  geom_node_text(aes(color = n, label = name), repel = TRUE)

}


# Code sourced from
# filtered_text <- combined_text[combined_text$n >= 100, ] #only select words with a frequency larger or equal to 100

# wordcloud(words = filtered_text$word, freq = filtered_text$n, scale=c(3,0.5), min.freq = 2, random.order = FALSE, colors= colorRampPalette(c("lightgray", "black"))(9))

```


```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-word-networks
#| layout-ncol: 2
#| fig-cap: "Word Networks Measured by Frequency and Correlation when Combining All Stream of Consciousness Novels"
#| fig-subcap: ["100 Frequency, 0.2 Correlation", "200 Frequency, 0.4 Correlation", "200 Frequency, 0.8 Correlation", "400 Frequency, 1 Correlation"] 

combined_text|>
  generate_word_graph(minimum_n = 100, minimum_correlation = 0.2)


combined_text|>
  generate_word_graph(minimum_n = 200, minimum_correlation = 0.4)

combined_text|>
  generate_word_graph(minimum_n = 200, minimum_correlation = 0.8)

combined_text|>
  generate_word_graph(minimum_n = 400, minimum_correlation = 1)
```
# Discussion

## Mental Health Vocabulary: Patterns and Trends 

Discuss vocabulary patterns and word trends

## Insights into Socio-Political Landscape of the West's Modernist Era 

The novels' linguistic patterns reflect the socio-political landscape of the Western hemisphere, from  late 19th century to the mid-20th century.

## Schizophrenic and Disassociative Tendencies in Female Stream of Consciousness


## Weaknesses 

### Lack of Thorough Word Cleaning

This includes words such as chapter titles, Roman numbers and personal names, affecting the integrity of data analysis ("Swann" being the most common word)

### Decontextualized Literature Works and Limiting Publication Editions

Words are singled out and analyzed without context which could have affected their intended meanings, especially in such a complex genre such as stream of consciousness. The limiting novel editions also doesn't make sure that their literary integrity are maintained and the analysis might have missed important texts of other editions. 

### Uneven Novel Length and Categorization of Authors

Since the novels are chosen based on their worldwide reception and canon, practical constraints like how all novels should be of similar length are ignored. This constraint can prevent one novel having more words than others, which can critically affect the integrity of the word frequency analysis, sentiment value and word networks where one novel dominates the others and skews the results.

In addition, these authors work are expansive and so choosing a select few to bind them to the SOC genre can be limiting as the SOC genre in itself is already an amalgamation of different literary trends. Thus, this can affect the integrity of the datasets.

### Project Gutenberg's Focus on the Canon

Along the search for other stream of consciousness authors to include in the generated datasets, only a few-those that are in the SOC canon, mostly white authors-are present in Project Gutenberg, without including lesser known SOC authors, which could have steared the data analysis, still, towards their preconception: being rueful and angst-ridden

## Moving Forward and Next Steps


\newpage

# Appendix

## Additional Data Details

```{r}
##| eval: true
##| echo: false
##| message: false
##| warning: false
#combined_books 
```

### Data Gathering

```{r fig.pos="H"}
##| echo: false
##| message: false
##| label: tbl-reasons-strip-search
##| tbl-cap:
  
```

### Data Cleaning


```{r fig.pos="H"}
##| echo: false
##| message: false
##| label: tbl-items-strip-search
##| tbl-cap: 


```


## Model Details {#sec-model-details}

## Posterior predictive check

## Diagnostics


\newpage

# References

