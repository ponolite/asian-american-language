---
title: "Stream of Consciousness Literature: A 'Joyceless' Linguistic Landscape" 
subtitle: "Exploring Word Frequency, Sentiment Value and Mental Health Themes in the Works of Joyce, Woolf, Proust, Mansfield and Eliot from Project Gutenberg"
author: Quang Mai
thanks: "Code and data are available at: https://github.com/ponolite/stream-consciousness-language.git"
date: today
date-format: long
abstract: "This project focuses on understanding the language used by renowned stream of consciousness (SOC) authors James Joyce, Virginia Woolf, Marcel Proust, Katherine Mansfield and T.S Eliot. By conducting word frequency analysis and sentiment analysis on these authors' nine novels, this paper aims to uncover shared linguistic patterns and gain insights into the authors' mental states. This paper attempts to offer insights into themes of self-identity, anxiety, disassociation and existential contemplation within Western society and its literary circle from late 19th to mid-20th century. (add one sentence on main results)"
format: pdf
number-sections: true
bibliography: references.bib
toc: true
---

```{r}
#| include: false
#| warning: false
#| message: false

library(tidyverse)
library(tidytext)
library(rmarkdown)
library(gutenbergr)
library(tm)
library(dplyr)
library(ggplot2)
library(scales)
library(knitr)
library(igraph)
library(widyr)
library(ggraph)
library(textdata)
library(arrow)
library(kableExtra)

portrait_clean <- read_parquet(here::here("data/analysis_data/portrait_clean.parquet"))
portrait_words <- read_parquet(here::here("data/analysis_data/portrait_words.parquet"))
swann_words <- read_parquet(here::here("data/analysis_data/swann_words.parquet"))
dalloway_words <- read_parquet(here::here("data/analysis_data/dalloway_words.parquet"))
bliss_words <- read_parquet(here::here("data/analysis_data/bliss_words.parquet"))
prufrock_words <- read_parquet(here::here("data/analysis_data/prufrock_words.parquet"))
combined_text <- read_parquet(here::here("data/analysis_data/combined_text.parquet"))
portrait <- read_csv(here::here("data/raw_data/portrait.csv"))
all_books <- read_csv(here::here("data/raw_data/all_books.csv"))
combined_books <- read_csv(here::here("data/raw_data/combined_books.csv"))

```

# Introduction

Stream of consciousness (SOC) is a narrative technique that aims to capture the continuous flow of thoughts, feelings, and sensations experienced by a character without conventional organization or punctuation [@resampling]. It mirrors the unpredictable and interconnected nature of human thought processes, often revealing the inner workings of the character's mind in an intimate and unfiltered manner [@flow]. In literature, most scholars agree that stream of consciousness reveals the complexities of mind-scapes, shedding light on the nuances of characters' emotional well-being and psychological struggles [@pathology]. As such, this paper has mined the texts of a total of nine novels from the volunteer archive, Project Gutenberg, to examine the mental health themes of famous stream of consciousness authors, namely by Joyce, Woolf, Proust, Mansfield and Eliot, from the modernist era of literature, spanning from late 19th century to mid-20th century [@gutenberg]. 

By analyzing these textual datasets through word frequency and sentiment analysis, I seek to pose and answer crucial questions: \textit{What are some important factors contributing to this relationship between mental health, disassociation and stream of consciousness? Moreover, how does this relationship vary differently across differnet demographics of authors, for instance, authors with different geographical locations and genders?} Understanding these dynamics is crucial in having an informed understanding of the West's late 19th to mid-20th century literature and even socio-political landscape, especially in regards to how authors and creative writers navigate and deal with then-taboo topics such as existential angst, mental health issues and disabilities.

Thus, the estimand is the correlation between mental health-related words in SOC literature, their frequency and sentiment value as provided by @rTidytext. This is considered in terms of nine selected SOC novels only, namely Joyce's \textit{A Portrait of the Artist as a Young Man and Chamber Music}; Woolf's \textit{Mrs Dalloway and Jacob's Room}; Proust's \textit{Swann Way}; Mansfield's \textit{Bliss and The Garden Party}; and Eliot's \textit{The Waste Land and The Love Song of J. Alfred Prufrock}. Through our analysis, we found that (percentage, number and data here, main results)...

To further understand the correlation between stream of consciousness novels and mental health themes, in [Introduction], the paper briefly discusses the nature of stream of consciousness literature, relevant authors and the works that I've chosen to analyze. Subsequently, in [Data] and [Results], I talk about the nature of the data obtained and analyze the results garnered from the data with suitable tables and charts. Next, [Discussion] provides further insights and future areas of study. Finally, [Conclusion] summarizes our main findings. To complete the paper, [Appendix] clarifies how each variable within each dataset is generated with relevant tables to accordingly demonstrate this.

The novel texts used for analysis were sourced from Project Gutenberg under the library `gutenbergr` [@rGuten] [@gutenberg]. Data was generated, extracted and cleaned using the open-source statistical programming language R [@r], leveraging functions from `tidyverse` [@rTidyverse], `tidytext` [@rTidytext], `rmarkdown` [@rMark], `dplyr` [@rDplyr], `ggplot2` [@rGgplot2], `scales` [@rScales], `here` [@rHere], `igraph` [@rIgraph], `widyr` [@rWidy], `ggraph` [@rGg], `textdata` [@rTextdata], `tm` [@rTm], `here` [@here], `kableExtra` [@kableExtra], `arrow` [@arrow], and `knitr` [@rKnitr].

# Data {#sec-data}

## Measurement

Two central variables in this paper are:

* **Word Frequency:** This variable captures the repetition of a single word (unigram), two-words combination (bigram) or three-words combination (trigram) throughout a SOC novel text, providing us with a thematic understanding of SOC literature.
* **Sentiment Value:** This variable enables us to analyze how every word is usually perceived emotionally, whether it be a qualitative feeling or if it is conveyed through a numerical value.

Out of two variables used, the first one, 'Word Frequency' usually captured as `n` or `frequency` in datasets, is directly quantified through tokenizing the novel texts using the package `tidytext` and its function `unnest_tokens()` [@rTidytext]. To do this, I first downloaded all nine novel texts from @gutenberg, and leveraged functions such as `unnest_tokens()` from @rTidytext to mine the texts, or separating it into individual words. Finally, I used `count()` to quantify the word frequency. 

The second variable used, 'Sentiment Value', is based on three English-based, general-purpose  "word-emotion and word-polarity association lexicons", sourced from Mohammad and Turney's expansive research along with efforts from Finn Årup Nielsen and Bing Liu and collaborators [@rTidytext] [@sentiment]. The three general-purpose lexicon that contributes to my sentiment analysis are [@rTidytext]:

- 'AFINN' from Finn Årup Nielsen, which assigns a numerical value from '-5 to 5' 
- 'bing' from Bing Liu and collaborators, which assigns if a word is 'positive' or negative'
- 'nrc' from Saif Mohammad and Peter Turney, which assigns a core emotional value to a word, such as 'fear', 'anger', 'sadness' or 'trust'.

In terms of measuring 'Sentiment Value', all three general-purpose lexicons are compiled through crowd-sourcing and directly surveying the public on how each word is emotionally perceived. A survey sample of how the word 'startle' is compiled within the 'nrc' lexicon is presented below [@sentiment]:

(@) Which word is closest in meaning (most related) to startle?
- automobile
- shake
- honesty
- entertain

(@) How positive (good, praising) is the word startle?:
- startle is not positive
- startle is weakly positive
- startle is moderately positive
- startle is strongly positive

(@) How negative (bad, criticizing) is the word startle?
- startle is not negative
- startle is weakly negative
- startle is moderately negative
- startle is strongly negative

After the survey results are garnered, researchers average the answers to sort each surveyed word into pre-defined categories, specifically '-5 to 5' for 'AFINN', 'postive' or 'negative' for 'bing', and 'anger' or 'fear' for 'nrc'. With the continuous work of compiling these lexicons spanning years and decades [@sentiment] comes these functions: `get_sentiments("bing")` and `get_sentiments("nrc")` and `get_sentiments("afinn")` in which I can use `inner_join` to categorize my existing datasets of novel texts into their sentiment value. Systematic and data-driven, these measurement methods ensure that all lexicons faithfully reflects each word's emotionality.

However, I do recognize how decontextualized and reductive this quantification of language can be. When it comes to understand such social and human artifacts as language or literary texts, much is dependent on their contextuality. As such, I will further discuss these weaknesses of the datasets under [Discussion].

## Source Data: Project Gutenberg

Founded in December 1, 1971 by Michael S. Hart, Project Gutenberg exclusively publishes literature in the public domain within the United States. Typically, submissions to Project Gutenberg are digitized editions of printed books, the majority of which were published over 95 years ago. To confirm public domain status, authors can use the copy.pglaf.org website [@gutenberg].

The archive depends mainly on volunteer efforts for support, and its literature is chosen and proofread by volunteers. However, the archive doesn't take copyrighted or modern items, even with permission. To submit work to the archive, you need to get copyright, scan or harvest images of book pages, spend hours proofreading and formatting, and ensure the eBook meets Project Gutenberg’s requirements, including being valid HTML, correctly spelled, and compliant  with Project Gutenberg’s requirement. Common points of failures for submitted works include:

- Crop marks or other printer's marks should not be used on any files.
- The book description should be in compliance with the rules listed here.
- Missing Pages
- Title missing on the front cover
- Incorrect pagination
- Books with typographical errors, such as misspellings or poor grammar.

In terms of format, Most new Project Gutenberg eBooks are in HTML format. Project Gutenberg will check each work's the HTML validity using the W3C’s online validator. The archive also askss for a plain text version whenever possible. This is because plain text has been around for a long time, is widely accessible on all devices and ensures long-term usability. PDF, Word, and other word processor formats are not used as master formats because they are harder to convert to HTML and update  [@gutenberg].

With these points being addressed and the impartial nature of the archive being publicly disclosed on its website, the source data in which I garner my literary texts are selected with strict quality and accuracy. However, there are potential spaces for biases such as selection bias where Project Gutenberg primarily hosts older works that have entered the public domain. Thus, archived works might gear towards certain genres, authors, or time periods, potentially limiting the diversity of the datasets for analysis, which will be further discussed below [@gutenberg].

### Data Cleaning and Word Tokenization

```{r}
#| echo: false
#| eval: true
#| label: tbl-joyce
#| tbl-cap: "An Examplary Table Containing Unprocessed Novel Text (James Joyce)"
#| warning: false

portrait |>
  rename("Book ID" = gutenberg_id,
         "Text" = text,
         "Book" = book,
         "Author" = author) |>
  head(3) |>
  kable(
    col.names = c("Book ID", "Text", "Book", "Author"),
    booktabs = TRUE
  ) |>
  kable_styling(latex_options = c("striped", "hold_position"), 
                bootstrap_options = "striped", 
                full_width = FALSE)

```

To garner the word count of SOC literature  using the library `gutenbergr`, I first downloaded the index of each respective SOC author's body of works using each author's name as outlined in Project Gutenberg database, namely Joyce, Mansfield, Eliot, Woolf, and Proust [@rGuten] ([Appendix]). Then, to create my own datasets containing the word frequency within each SOC author's texts, I used the identification number of the desired literary work and the function `gutenberg_download` to upload the HTML texts into individual csv-and later on, parquet-datasets, as observed in @tbl-joyce for James Joyce.

```{r}
#| echo: false
#| eval: true
#| label: tbl-joyce-token
#| tbl-cap: "Tokenized Novel Text & Word Count (James Joyce)"
#| tbl-subcap: 
#|   - "Tokenized Text"
#|   - "Word Count"
#| layout-ncol: 2
#| warning: false
#| message: false


portrait_clean |>
  rename("Book ID" = gutenberg_id,
         "Book" = book,
         "Author" = author,
         "Word" = word) |>
  tail(3) |>
  kable(
    col.names = c("Book ID", "Book", "Author", "Word"),
    booktabs = TRUE
  ) |>
  kable_styling(latex_options = c("striped", "hold_position"), 
                bootstrap_options = "striped", 
                full_width = FALSE)

portrait_words |>
  rename("Word" = word) |>
  head(5) |>
  kable(
    col.names = c("Word", "Count"),
    booktabs = TRUE
  ) |>
  kable_styling(latex_options = c("striped", "hold_position"), 
                bootstrap_options = "striped", 
                full_width = FALSE)


```

Next, observable in @tbl-joyce-token, to measure the word frequency of each literary text, I first tokenized or separated the texts into individual chunks of words using `unnest_tokens()` [@rTidytext].In addition, to account for stop words like, a, of, and, etc., I leveraged the dataset `stop_words`and the function `anti_join` from @rTidytext to exclude all stop words from my self-generated datasets of literary texts, ensuring data validity and meaningful analysis.

Then, to quantify the number of times each word appears in each text, I used `count()` (@tbl-joyce-token). The result manifests into @fig-count. The figure demonstrates that beside the top frequencies of personal names, most of the words are abstract nouns that revolve around the nature of time, and life, e.g. god (appearing 194 times in Joyce's), time (appearing in 4 authors' texts, 121 times for Joyce's, 77 times for Woolf's, 421 times for Proust's, 23 times for Eliot), mind (108 times in Joyce's and 196 times in Proust's), life (appearing 266 times in Proust's and 131 times in Joyce's), etc. This further exemplifies the sense of disassociation, temporality and non-linearity commonly associated to stream-of-consciousness literature and more broadly with mental health themes ([@flow], [@pathology], [@resampling]).


\newpage

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-count
#| layout-ncol: 2
#| fig-cap: "Comparative Analysis of Top 20 Word Frequencies from Famous SOC Authors"
#| fig-subcap: ["James Joyce", "Virginia Woolf", "Marcel Proust", "T.S. Eliot", "Katherine Mansfield"]

portrait_words |> head(20) |>
ggplot(aes(x = n, y = reorder(word, n))) +
  geom_bar(stat = "identity", fill = "darkgrey") +
  geom_text(aes(label = n), hjust = -0.3, vjust = 0.5, color = "grey40", size = 3) +
  labs(x = "Frequency", y = "Word")

dalloway_words |> head(20) |>
ggplot(aes(x = n, y = reorder(word, n))) +
  geom_bar(stat = "identity", fill = "darkgrey") +
  geom_text(aes(label = n), hjust = -0.3, vjust = 0.5, color = "grey40", size = 3) +
  labs(x = "Frequency", y = "Word")

swann_words |> head(20) |>
ggplot(aes(x = n, y = reorder(word, n))) +
  geom_bar(stat = "identity", fill = "darkgrey") +
  geom_text(aes(label = n), hjust = -0.3, vjust = 0.5, color = "grey40", size = 3) +
  labs(x = "Frequency", y = "Word")

prufrock_words |> head(20) |>
ggplot(aes(x = n, y = reorder(word, n))) +
  geom_bar(stat = "identity", fill = "darkgrey") +
  geom_text(aes(label = n), hjust = -0.3, vjust = 0.5, color = "grey40", size = 3) +
  labs(x = "Frequency", y = "Word")

bliss_words |> head(20) |>
ggplot(aes(x = n, y = reorder(word, n))) +
  geom_bar(stat = "identity", fill = "darkgrey") +
  geom_text(aes(label = n), hjust = -0.3, vjust = 0.5, color = "grey40", size = 3) +
  labs(x = "Frequency", y = "Word") 


```


### Comparative Word Frequency

```{r}
#| echo: false
#| eval: true
#| label: tbl-frequency
#| tbl-cap: "Word Frequency of Stream of Consciousness Novels, A Comparison Between Five Authors "
#| warning: false

frequency <- bind_rows(mutate(portrait_words, author = "James Joyce"),
                       mutate(swann_words, author = "Marcel Proust"),
                       mutate(dalloway_words, author = "Virginia Woolf"),
                       mutate(bliss_words, author = "Katherine Mansfield"),
                       mutate(prufrock_words, author = "T.S. Eliot")) |>
  mutate(word = str_extract(word, "[a-z']+")) |>
  count(author, word) |>
  group_by(author) |>
  mutate(proportion = n / sum(n)) |>
  select(-n) |>
  pivot_wider(names_from = author, values_from = proportion) |>
  filter(if_all(everything(), ~is.na(.) | !is.na(.)))

frequency |>
  rename("Word" = word) |>
  head(5) |>
  kable(
    col.names = c("Word", "James Joyce", "Katherine Mansfield", "Marcel Proust", "T.S. Eliot", "Virignia Woolf"),
    booktabs = TRUE
  ) |>
    kable_styling(latex_options = c("striped", "hold_position"), bootstrap_options = "striped", full_width = FALSE)


```


To accurately compare word frequency among SOC authors, from @tbl-frequency, I convert each word frequency into a percentage. This is done by using `mutate` to calculate the word frequency of each word relative to the total word frequency of each author. Due to the different number of words present in each author's literary works, this method accounts for the inconsistencies of between each author's word count.

```{r}
#| echo: false
#| eval: true
#| label: tbl-boxplot 
#| tbl-cap: "Overall Boxplot Summary Statistics of all Word Frequency Percentages (AFINN Sentiment)"
#| warning: false

# Calculate summary statistics
frequency_long |>
  group_by(frequency) %>%
  summarise(
    min = min(value),
    q1 = quantile(value, probs = 0.25),
    median = median(value),
    mean = mean(value),
    q3 = quantile(value, probs = 0.75),
    max = max(value),
    sd = sd(value)
  ) |>
    head(10) |>
  kable(
    col.names = c("Frequency", "Min", "Q1", "Median", "Mean", "Q3", "Max", "SD"),
    booktabs = TRUE
  ) |>
  kable_styling(latex_options = c("striped", "hold_position"), 
                bootstrap_options = "striped", 
                full_width = FALSE)


```

@fig-sentiment-frequency and @tbl-boxplot captures the data garnered. For the NRC index, for all authors, the lower word frequency percentage ranges from 0.0000819 to 0004255 and are largely words that carry a mixture of emotional connotations such as, joy, surprise, positive, disgust and anticipation. However, the higher word frequency percentage, ranging from 0,0004255 to 0.0008511, mostly contains words with negative connotations like fear and anger, that weighs a -1.875 median on a scale between -5 to 5 in the AFINN index. Similarly, for the Bing index, the higher word frequency ranging from 0,0004255 to 0.0008511 percentages largely contains words that carry negative connotations, that weighs approximately a -1.875 median on a scale between -5 to 5 in the AFINN index. 

Overseeing the entire dataset, @tbl-boxplot demonstrates that, for all distinct word frequency percentages, the median sentiment value is -2 on the scale between -5 and 5. More specifically, words that appear most frequently, or words with the frequency percentage of 0.0008511, have the lowest mean sentiment value-or the most negative connotation of-2.33 on the scale between -5 and 5 in the AFINN sentiment index. This summary statistics of the gathered data only further shows how the SOC literary landscape mostly associates with words that carry more negative or even extreme connotations often associated with mental health themes, and topics such as depression, disassociation or schizophrenia [@pathology].

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-sentiment-frequency
#| layout-ncol: 2
#| fig-cap: "Overall Word Frequency and Sentiment Analysis"
#| fig-subcap: ["Bing lexicon", "NRC lexicon"]


# Reshape data for plotting
bing_lexicon <- get_sentiments("bing") %>%
  rename(sentiment_binary = sentiment)

frequency_long <- pivot_longer(frequency, 
                               cols = c("James Joyce", "Marcel Proust", "Virginia Woolf", "Katherine Mansfield", "T.S. Eliot"), 
                               names_to = "author", values_to = "frequency") |>
  inner_join(bing_lexicon) |>
  inner_join(get_sentiments("afinn")) |>
  inner_join(get_sentiments("nrc")) 

frequency_long <- na.omit(frequency_long) 

ggplot(frequency_long, aes(x = frequency, y = value, fill = sentiment_binary)) +
  geom_boxplot() +
  labs(title = "Boxplot of Sentiment Scores by Author (Bing)",
       x = "Word Frequency Percentage",
       y = "Sentiment Value (AFINN)",
       fill = "Sentiment Associated") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 


ggplot(frequency_long, aes(x = frequency, y = value, fill = sentiment)) +
  geom_boxplot() +
  labs(title = "Boxplot of Sentiment Scores by Author (NRC)",
       x = "Word Frequency Percentage",
       y = "Sentiment Value (AFINN)",
       fill = "Sentiment Associated") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) 


```

## Data Limitations

### Lack of Thorough Word Cleaning

With the large amount of different literary texts need processing by myself, it's hard to truly conduct thorough word processing. Certain textual elements, while can have their frequencies accounted for, can't have sentiment analysis due to their factual nature. These textual elements might include things like chapter titles, Roman numbers and personal names, which can strongly skew and affect the data integrity. As observed in @fig-count, "Swann", "Stephen" or "Jacob" are the most repeated words in Proust's, Joyce's and Woolf's, proving this data limitation.

### Potential Measurement Errors

The actual raw text data sourced from Project Gutenberg may be susceptible to measurement errors due to various factors, such as selection bias towards older, Western and canonical texts, social desirability bias that edits out certain political elements, memory lapses, or misinterpretations of literary texts by voluntary proofreaders. While the archive has strict guidelines to minimize these errors, they cannot be entirely eliminated.

### Uneven Text Length 

I chose literary texts based on their global reception and canonical status within the stream-of-consciousness genre. This decision involved forgoing certain practical considerations, such as ensuring similar text lengths across all works by each author. While this approach enables a thorough exploration of word frequency analysis, sentiment value, and word networks within the SOC genre, it also has the potential to emphasize the frequencies of certain words from specific authors more than others due to the longer text length of those authors. This could critically affect the integrity of the data analysis.

## Biased Author Selection

Furthermore, SOC literature is expansive, spanning a wide range of themes, styles, and narrative techniques. By exclusively representing the genre through a select group of canonical Western authors, I risk constraining the genre's diversity. By oversimplifying the complexity of the the dynamic literary genre, I also affect the integrity of the datasets and its correlation to mental health themes.

# Results

## The Dominant Vocabulary of SOC Literature

## Sentiment Analysis

Leveraging setiment analysis from @sentiment

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-sentiment-category
#| layout-ncol: 2
#| fig-cap: "Categorical Sentiment Analysis of All SOC Novel Texts by Authors"
#| fig-subcap: ["Bing lexicon", "NRC lexicon"]

bing_lexicon <- get_sentiments("bing") %>%
  rename(sentiment_binary = sentiment)

sentiment_combined <- combined_text |>
  inner_join(bing_lexicon) |>
  inner_join(get_sentiments("afinn")) |>
  inner_join(get_sentiments("nrc"))

sentiment_category_binary <- sentiment_combined |>
  group_by(author, sentiment_binary) |>
  count() |>
  group_by(author) |>
  mutate(percentage = n / sum(n) * 100)  

# Plot sentiment values
ggplot(sentiment_category_binary, aes(x = author, fill = sentiment_binary, y = percentage)) +
  geom_bar(stat = "identity") +
  labs(
       x = "Author", y = "Percentage") +
  scale_fill_manual(values = c("positive" = "gray80", "negative" = "gray20", "neutral" = "gray50")) + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

sentiment_category <- sentiment_combined |>
  group_by(author, sentiment) |>
  count() |>
  group_by(author) |>
  mutate(percentage = n / sum(n) * 100)  |>
  group_by(author) |>
  arrange(desc(percentage))

# Plot sentiment values
ggplot(sentiment_category, aes(x = author, fill = sentiment, y = percentage)) +
  geom_bar(stat = "identity") +
  labs(
       x = "Author", y = "Percentage") +
  scale_fill_manual(values = c("negative" = "gray1", "sadness" = "gray10", "anger" = "gray20", "disgust" = "gray30", "fear" = "gray40", "joy" = "gray50", "trust" = "gray60", "anticipation" = "gray70", "positive" = "gray80", "surprise" = "gray90")) + 
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))


```

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-sentiment-number
#| fig-cap: "Numerical Sentiment Analysis of All SOC Novel Texts by Authors (AFINN lexicon)"

sentiment_value <- sentiment_combined |>
  inner_join(get_sentiments("bing")) |>
  group_by(author, value, sentiment) |>
  count() |>
  group_by(author) |>
  mutate(percentage = n / sum(n) * 100)  

ggplot(sentiment_value, aes(x = value, y = percentage, color = sentiment, group = sentiment)) +
  geom_line() +
  facet_wrap(~ author, scales = "free") +
  labs(
       x = "Sentiment Value", y = "Percentage") +
  scale_color_manual(values = c("positive" = "black", "negative" = "gray")) + # Adjust line colors
  theme_minimal()
```


## Gendered Mental Landscape of Stream of Consciousness Novels

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-word-gender
#| layout-ncol: 2
#| fig-cap: "Comparative Analysis of Word Frequency in Female and Male Stream of Consciousness Authors"
#| fig-subcap: ["Female Authors", "Male Authors"]


# Calculate the word frequency over all unique words and bind all frequency rate of authors together to conduct a comparative comparison
# Code referenced from https://medium.com/the-data-nudge/nlp-basics-exploring-word-frequency-with-the-tidytext-r-package-ac35a6d805f4

  
frequency_female <- bind_rows(mutate(dalloway_words, author = "Virginia Woolf"),
                              mutate(bliss_words, author = "Katherine Mansfield")) |>
  mutate(word = str_extract(word, "[a-z']+")) |>
  count(author, word) |>
  group_by(author) |>
  mutate(proportion = n / sum(n)) |>
  select(-n) |>
  pivot_wider(names_from = author, values_from = proportion) |>
  pivot_longer(`Virginia Woolf`,
               names_to = "author", values_to = "proportion")

ggplot(frequency_female, aes(x = proportion, y = `Katherine Mansfield`, color = abs(`Katherine Mansfield` - proportion))) +
  geom_abline(color = "gray50", lty = 2) +
  geom_jitter(alpha = 0.1, size = 1, width = 0.5, height = 0.5) +  
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = scales::percent_format()) +
  scale_y_log10(labels = scales::percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), 
                       low = "blue2", high = "gray50") +
  facet_wrap(~author, ncol = 1) +
  theme(legend.position="none") +
  labs(y = "Katherine Mansfield", x = NULL)

frequency_male <- bind_rows(
                       mutate(swann_words, author = "Marcel Proust"),
                       mutate(prufrock_words, author = "T.S. Eliot"),
                       mutate(portrait_words, author = "James Joyce")) |>
  mutate(word = str_extract(word, "[a-z']+")) |>
  count(author, word) |>
  group_by(author) |>
  mutate(proportion = n / sum(n)) |>
  select(-n) |>
  pivot_wider(names_from = author, values_from = proportion) |>
  pivot_longer(`Marcel Proust`:`James Joyce`,
               names_to = "author", values_to = "proportion")

ggplot(frequency_male, aes(x = proportion, y = `T.S. Eliot`, color = abs(`T.S. Eliot` - proportion))) +
  geom_abline(color = "gray50", lty = 2) +
  geom_jitter(alpha = 0.1, size = 1.5, width = 0.8, height = 0.8) +  
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), 
                       low = "blue2", high = "gray100") +
  facet_wrap(~author, ncol = 2) +
  theme(legend.position="none") +
  labs(y = "T.S. Eliot", x = NULL)


```

### Comparing SOC Literature's Female Authors

### Comparing SOC Literature's Male Authors

## Transnational SOC Novels and Mental Health Themes

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-frequency-int
#| fig-cap: "Comparative Analysis of Word Frequency in Transnational Stream of Consciousness Authors"

frequency_international <- bind_rows(
                       mutate(swann_words, author = "Marcel Proust"),
                       mutate(bliss_words, author = "Katherine Mansfield"),
                       mutate(portrait_words, author = "James Joyce")) |>
  mutate(word = str_extract(word, "[a-z']+")) |>
  count(author, word) |>
  group_by(author) |>
  mutate(proportion = n / sum(n)) |>
  select(-n) |>
  pivot_wider(names_from = author, values_from = proportion) |>
  pivot_longer(`Katherine Mansfield`:`James Joyce`,
               names_to = "author", values_to = "proportion")

ggplot(frequency_international, aes(x = proportion, y = `Marcel Proust`, color = abs(`Marcel Proust` - proportion))) +
  geom_abline(color = "gray50", lty = 2) +
  geom_jitter(alpha = 0.05, size = 1, width = 0.8, height = 0.8) +  
  geom_text(aes(label = word), check_overlap = TRUE, vjust = 1.5) +
  scale_x_log10(labels = percent_format()) +
  scale_y_log10(labels = percent_format()) +
  scale_color_gradient(limits = c(0, 0.001), 
                       low = "blue2", high = "gray100") +
  facet_wrap(~author, ncol = 1) +
  theme(legend.position="none") +
  labs(y = "Marcel Proust", x = NULL)

```

## Combined Texts: Trends, Word Networks, Bigram and Trigram Analsis

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false

## Code sourced from https://www.youtube.com/watch?v=ae_XVhjHd_o

generate_word_graph <- function(combined_text,
                                minimum_n = 100,
                                minimum_correlation = 0.2) {

combined_text_count <- combined_text |>
  count(word, sort = TRUE) |>
  filter(n >= 200) 

combined_correlations <- combined_text |>
  semi_join(combined_text_count, by = "word") |>
  pairwise_cor(item = word, feature = book) |>
  filter(correlation >= 0.2)

graph_from_data_frame(d = combined_correlations, #create graphs of networks of words
                      vertices = combined_text_count |>
                      semi_join(combined_correlations, by = c("word" = "item1"))) |>
  ggraph(layout = "fr") +
  geom_edge_link(aes(alpha = correlation), alpha = 0.05) +
  geom_node_point() +
  geom_node_text(aes(color = n, label = name), repel = TRUE)

}


# Code sourced from
# filtered_text <- combined_text[combined_text$n >= 100, ] #only select words with a frequency larger or equal to 100

# wordcloud(words = filtered_text$word, freq = filtered_text$n, scale=c(3,0.5), min.freq = 2, random.order = FALSE, colors= colorRampPalette(c("lightgray", "black"))(9))

```


```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
#| label: fig-word-networks
#| layout-ncol: 2
#| fig-cap: "Word Networks Measured by Frequency and Correlation when Combining All Stream of Consciousness Novels"
#| fig-subcap: ["100 Frequency, 0.2 Correlation", "200 Frequency, 0.4 Correlation", "200 Frequency, 0.8 Correlation", "400 Frequency, 1 Correlation"] 

combined_text|>
  generate_word_graph(minimum_n = 100, minimum_correlation = 0.2)


combined_text|>
  generate_word_graph(minimum_n = 200, minimum_correlation = 0.4)

combined_text|>
  generate_word_graph(minimum_n = 200, minimum_correlation = 0.8)

combined_text|>
  generate_word_graph(minimum_n = 400, minimum_correlation = 1)
```
# Discussion

## Mental Health Vocabulary: Patterns and Trends 

Discuss vocabulary patterns and word trends

## Insights into Socio-Political Landscape of the West's Modernist Era 

pathological consequences of the constant
shifts of identity in migrant characters. Most postcolonial studies contend that
marginalization occasioned by the dominant group result in neurotic conditions in
members of the minority group.

The novels' linguistic patterns reflect the socio-political landscape of the Western hemisphere, from  late 19th century to the mid-20th century.

## Schizophrenic and Disassociative Tendencies in Female Stream of Consciousness


## Weaknesses 

### Lack of Thorough Word Cleaning

This includes words such as chapter titles, Roman numbers and personal names, affecting the integrity of data analysis ("Swann" being the most common word)

### Decontextualized Literature Works and Limiting Publication Editions

Words are singled out and analyzed without context which could have affected their intended meanings, especially in such a complex genre such as stream of consciousness. The limiting novel editions also doesn't make sure that their literary integrity are maintained and the analysis might have missed important texts of other editions. 

While these datasets aim to illuminate on the general time trends of childlessness with each variable measured, they are often de-contextualized for the same purpose. For instance, in Table 6, there is no clarifying note on whether people who declared themselves as ‘divorced’ are divorced once or more. This can be extremely narrowing, and exclude nuances when analyzing the contexts behind childlessness.
### Uneven Novel Length and Categorization of Authors

Since the novels are chosen based on their worldwide reception and canon, practical constraints like how all novels should be of similar length are ignored. This constraint can prevent one novel having more words than others, which can critically affect the integrity of the word frequency analysis, sentiment value and word networks where one novel dominates the others and skews the results.

In addition, these authors work are expansive and so choosing a select few to bind them to the SOC genre can be limiting as the SOC genre in itself is already an amalgamation of different literary trends. Thus, this can affect the integrity of the datasets.

### Project Gutenberg's Focus on the Canon

Along the search for other stream of consciousness authors to include in the generated datasets, only a few-those that are in the SOC canon, mostly white authors-are present in Project Gutenberg, without including lesser known SOC authors, which could have steared the data analysis, still, towards their preconception: being rueful and angst-ridden

## Moving Forward and Next Steps


\newpage

# Appendix

## Additional Data Details

```{r}
##| eval: true
##| echo: false
##| message: false
##| warning: false
#combined_books 
```

### Data Gathering

```{r fig.pos="H"}
##| echo: false
##| message: false
##| label: tbl-reasons-strip-search
##| tbl-cap:
  
```

### Data Cleaning


```{r fig.pos="H"}
##| echo: false
##| message: false
##| label: tbl-items-strip-search
##| tbl-cap: 


```


\newpage

# References

